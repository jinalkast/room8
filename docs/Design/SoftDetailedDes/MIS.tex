\documentclass[12pt, titlepage]{article}

\usepackage{amsmath, mathtools}

\usepackage[round]{natbib}
\usepackage{amsfonts}
\usepackage{amssymb}
\usepackage{graphicx}
\usepackage{colortbl}
\usepackage{xr}
\usepackage{hyperref}
\usepackage{longtable}
\usepackage{xfrac}
\usepackage{tabularx}
\usepackage{float}
\usepackage{siunitx}
\usepackage{booktabs}
\usepackage{multirow}
\usepackage[section]{placeins}
\usepackage{caption}
\usepackage{fullpage}

\hypersetup{
bookmarks=true,     % show bookmarks bar?
colorlinks=true,       % false: boxed links; true: colored links
linkcolor=red,          % color of internal links (change box color with linkbordercolor)
citecolor=blue,      % color of links to bibliography
filecolor=magenta,  % color of file links
urlcolor=cyan          % color of external links
}

\usepackage{array}

\externaldocument{../../SRS/SRS}

\input{../../Comments}
\input{../../Common}

\begin{document}

\title{Module Interface Specification for \progname{}}

\author{\authname}

\date{\today}

\maketitle

\pagenumbering{roman}

\section{Revision History}

\begin{tabularx}{\textwidth}{p{3cm}p{2cm}X}
\toprule {\bf Date} & {\bf Version} & {\bf Notes}\\
\midrule
Date 1 & 1.0 & Notes\\
Date 2 & 1.1 & Notes\\
\bottomrule
\end{tabularx}

~\newpage

\section{Symbols, Abbreviations and Acronyms}

See SRS Documentation at \wss{give url}

\wss{Also add any additional symbols, abbreviations or acronyms}

\newpage

\tableofcontents

\newpage

\pagenumbering{arabic}

\section{Introduction}

The following document details the Module Interface Specifications (MIS) for
\progname{}, a suite of tools for providing roommates in shared living situations tools to settle common disputes and keep track of shared responsibilities. Beginning from and following \hyperref[Start]{Section 7} the MIS for all modules in the \href{https://github.com/jinalkast/room8/tree/main/docs/Design/SoftArchitecture}{Module Guide} (MG) can be found. Potential readers of this document include new developers, and maintainers looking for clarity on the implementation of modules.\\

Complementary documents include the System Requirement Specifications
and Module Guide.  The full documentation and implementation can be
found at \url{https://github.com/jinalkast/room8/tree/main}.  

\section{Notation}

\wss{You should describe your notation.  You can use what is below as
  a starting point.}

The structure of the MIS for modules comes from \citet{HoffmanAndStrooper1995},
with the addition that template modules have been adapted from
\cite{GhezziEtAl2003}.  The mathematical notation comes from Chapter 3 of
\citet{HoffmanAndStrooper1995}.  For instance, the symbol := is used for a
multiple assignment statement and conditional rules follow the form $(c_1
\Rightarrow r_1 | c_2 \Rightarrow r_2 | ... | c_n \Rightarrow r_n )$.

The following table summarizes the primitive data types used by \progname. 

\begin{center}
\renewcommand{\arraystretch}{1.2}
\noindent 
\begin{tabular}{l l p{7.5cm}} 
\toprule 
\textbf{Data Type} & \textbf{Notation} & \textbf{Description}\\ 
\midrule
character & char & a single symbol or digit\\
integer & $\mathbb{Z}$ & a number without a fractional component in (-$\infty$, $\infty$) \\
natural number & $\mathbb{N}$ & a number without a fractional component in [1, $\infty$) \\
real & $\mathbb{R}$ & any number in (-$\infty$, $\infty$)\\
\bottomrule
\end{tabular} 
\end{center}

\noindent
The specification of \progname \ uses some derived data types: sequences, strings, and
tuples. Sequences are lists filled with elements of the same data type. Strings
are sequences of characters. Tuples contain a list of values, potentially of
different types. In addition, \progname \ uses functions, which
are defined by the data types of their inputs and outputs. Local functions are
described by giving their type signature followed by their specification.

\section{Module Decomposition}

The following table is taken directly from the Module Guide document for this project.

\begin{table}[h!]
\centering
\begin{tabular}{p{0.3\textwidth} p{0.6\textwidth}}
\toprule
\textbf{Level 1} & \textbf{Level 2}\\
\midrule

{Hardware-Hiding} & ~ \\
\midrule

\multirow{7}{0.3\textwidth}{Behaviour-Hiding} & Input Parameters\\
& Output Format\\
& Output Verification\\
& Temperature ODEs\\
& Energy Equations\\ 
& Control Module\\
& Specification Parameters Module\\
\midrule

\multirow{3}{0.3\textwidth}{Software Decision} & {Sequence Data Structure}\\
& ODE Solver\\
& Plotting\\
\bottomrule

\end{tabular}
\caption{Module Hierarchy}
\label{TblMH}
\end{table}

\newpage
~\newpage

\section{MIS of \wss{Module Name}} \label{Module} 

\wss{You can reference SRS labels, such as R\ref{R_Inputs}.}

\wss{It is also possible to use \LaTeX for hypperlinks to external documents.}

\subsection{Module}

\wss{Short name for the module}

\subsection{Uses}


\subsection{Syntax}

\subsubsection{Exported Constants}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
\wss{accessProg} & - & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

\wss{Not all modules will have state variables.  State variables give the module
  a memory.}

\subsubsection{Environment Variables}

\wss{This section is not necessary for all modules.  Its purpose is to capture
  when the module has external interaction with the environment, such as for a
  device driver, screen interface, keyboard, file, etc.}

\subsubsection{Assumptions}

\wss{Try to minimize assumptions and anticipate programmer errors via
  exceptions, but for practical purposes assumptions are sometimes appropriate.}

\subsubsection{Access Routine Semantics}

\noindent \wss{accessProg}():
\begin{itemize}
\item transition: \wss{if appropriate} 
\item output: \wss{if appropriate} 
\item exception: \wss{if appropriate} 
\end{itemize}

\wss{A module without environment variables or state variables is unlikely to
  have a state transition.  In this case a state transition can only occur if
  the module is changing the state of another module.}

\wss{Modules rarely have both a transition and an output.  In most cases you
  will have one or the other.}

\subsubsection{Local Functions}

\wss{As appropriate} \wss{These functions are for the purpose of specification.
  They are not necessarily something that is going to be implemented
  explicitly.  Even if they are implemented, they are not exported; they only
  have local scope.}
\newpage

\section{MIS of Sensor Reading Module} \label{Start} 

\subsection{Module}

M1: Sensor Reading Module.

\subsection{Uses}
Used to gather data on user presence in shared space to determine when to take before and after pictures of the shared space.


\subsection{Syntax}

\subsubsection{Exported Constants}
motionPresent: boolean

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
timeMotion & timesOfMotion & timeMotionDetected & - \\
detector & sensorData & motionPresent & - \\
insertTime & - & - & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}

timesOfMotion: List[datetime] - List of time when motion was detected by the sensor.

\subsubsection{Environment Variables}
sensorData: sensorDataType - Data acquired by the sensor with data type supported by sensor.

\subsubsection{Access Routine Semantics}

\noindent timeMotion(timesOfMotion: datetime) -$>$ datetime:
\begin{itemize}
\item input: List of time stamps of when motion was detected. 
\item output: Last timestamp of when motion was detected. 
\end{itemize}

\noindent detector(sensorData: sensorDataType) -$>$ boolean:
\begin{itemize}
\item input: Data received from sensor. 
\item output: True of false value depending on if motion was detected. 
\end{itemize}

\subsubsection{Local Functions}

insertTime() - Inserting time stamp into timesOfMotion variable.


\newpage

\section{MIS of Image Capture Module} \label{Module} 

\subsection{Module}

M2: Image Capture Module.

\subsection{Uses}
Capture image of shared space using camera system.

\subsection{Syntax}

\subsubsection{Exported Constants}
image: png

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{4cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
captureImage & - & image & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{Access Routine Semantics}

\noindent captureImage() -$>$ 'png':
\begin{itemize}
\item output: Image taken.
\end{itemize}

\subsubsection{Assumptions}
\begin{itemize}
\item captureImage will only be called when picture is needed to be taken, that is before user starts using shared space and five minutes after user has left shared space.
\end{itemize}


\newpage

\section{MIS of Image Upload Module} \label{Module} 

\subsection{Module}

M3: Image Upload Module.

\subsection{Uses}
Uploads the captured image to Raspberry Pi for the cleanliness detection system to use for analysis.

\subsection{Syntax}

\subsubsection{Exported Constants}
imgUploadErrorMessage : str - Message for cause of upload error.

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{3cm} p{2cm} p{2cm} p{5cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
uploadImage & image & - & imgUploadErrorMessage \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}


\subsubsection{Access Routine Semantics}

\noindent uploadImage(image: png):
\begin{itemize}
\item input: Image taken from camera. 
\item exception: 
	\begin{itemize}
		\item ImageUploadInterrupted: Raised if error occurs during image upload.
	\end{itemize} 
\end{itemize}

\subsubsection{Assumptions}
\begin{itemize}
	\item Network is stable and never causes error in image upload.
	\item Power source is stable and never causes error in image upload.
\end{itemize}

\subsubsection{Local Functions}

captureImage() -$>$ png - Takes picture to be uploaded.

\newpage

\section{MIS of Request Listener Module} \label{Module} 


\subsection{Module}

M7: Request Listener Module.

\subsection{Uses}
Exposes cleanliness detector to camera and image by making it an application programming interface.

\subsection{Syntax}

\subsubsection{Exported Constants}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{2cm} p{4cm} p{4cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
getImages & - & images & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}


\subsubsection{Access Routine Semantics}

\noindent getImages() -$>$ List[png]:
\begin{itemize}
\item output: Two most recent images where one is the before and other is the after state of shared space after user is finished.
\end{itemize}

\newpage

\section{MIS of PreprocessingModule} \label{Module} 

\subsection{Module}

PreprocessingModule

\subsection{Uses}
The Preprocessing Module is used for preparing raw images (i.e. from the Image Upload module) to be submitted to subsequent modules (i.e. Object Detection and Scoring). A series of transformations is applied to the image.

\subsection{Syntax}

\subsubsection{Exported Constants}

\begin{itemize}
  \item SUPPORTED{\_}FORMATS: List[str] = ["JPEG", "PNG"]
  \item DEFAULT{\_}TRANSFORMS: torchvision.transforms.Compose\: A default set of PyTorch transformations, including resizing, normalization, and optional filtering
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5cm} p{3cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
process{\_}image & image: Image & Tensor & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None



\subsubsection{Environment Variables}
\begin{itemize}
  \item ImageUploadModule: Module from which input image is recieved
\end{itemize}

\subsubsection{Assumptions}
\begin{itemize}
  \item The input image is in a valid format supported by PyTorch (e.g. JPEG, PNG)
  \item PyTorch and torchvision libraries are installed and functional
  \item Network connectivity is stable for receiving images through the cloud network
\end{itemize}


\subsubsection{Access Routine Semantics}

\noindent process{\_}image(image: Image):
\begin{itemize}
\item transition: Applies a sequence of PyTorch transformations to the input image 
\item output: Returns the transformed image as a Pytorch tensor, ready for subsequent object detection
\item exception: 
\begin{itemize}
  \item InvalidImageFormatException: Raised if the input image format is unsupported
  \item TransformationError: Raised if an error occurs during transformations
\end{itemize}

\end{itemize}
\noindent process{\_}image(image: Image):
\begin{itemize}
  \item transition: Applies pixel map transformations (e.g. resizing, cropping, filtering) to the input image
  \item output: Returns the transformed image
  \item exception: 
  \begin{itemize}
    \item TransformationError: Raised if an error occurs during transformations
  \end{itemize}
  
  \end{itemize}

\subsubsection{Local Functions}

\begin{itemize}
  \item validate{\_}image{\_}format(image: Image) $\rightarrow$ bool: Checks if the input image format is supported
  \item create{\_}transforms() $\rightarrow$ torchvision.transforms.Compose\: Creates a PyTorch Compose object for the default set of transformations
  \item apply{\_}transforms(image: Image, transforms: torchvision.transforms.Compose) $\rightarrow$ Tensor: Applies the given transformations to the input image
\end{itemize}

\newpage

\section{MIS of ObjectDetection} \label{Module} 

\subsection{Module}

ObjectDetectionModule

\subsection{Uses}
To detect objects in an input tensor (preprocessed image) using a pretrained object detector (e.g. Faster R-CNN ResNet-50 FPN model). The output is a list of detected objects, where each object is represented as a HouseObject.

\subsection{Syntax}

\subsubsection{Exported Constants}

\begin{itemize}
  \item MODEL{\_}NAME: str = "FasterRCNN{\_}ResNet50{\_}FPN"
  \item CONFIDENCE{\_}THRESHOLD: float = 0.5 (minimum confidence score for object detection results)
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5cm} p{3cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
detect{\_}objects & input{\_}tensor: Tensor & List[HouseObject] & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
	\item self.model: torchvision.models.detection.FasterRCNN
\end{itemize}


\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
  \item The input tensor is correctly preprocessed and normalized according to the requirements of the Faster R-CNN model
  \item PyTorch and torchvision libraries are installed and functional
\end{itemize}


\subsubsection{Access Routine Semantics}

\noindent detect{\_}objects
\begin{itemize}
\item transition: Uses the pretrained Faster R-CNN model to detect objects in the input tensor, filters results based on the confidence threshold
\item output: Returns a list of detected objects, where each object is represented as a HouseObject
\item exception: 
\begin{itemize}
  \item ModelNotLoadedException: Raised if the model fails to load
  \item DetectionError: Raised if an error occurs during detection process
\end{itemize}

\end{itemize}


\subsubsection{Local Functions}

\begin{itemize}
  \item load{\_}model() $\rightarrow$ torchvision.models.detection.FasterRCNN: Loads pretrained Faster R-CNN ResNet-50 FPN model
  \item filter{\_}detections(detections: List[Dict], threshold: float) $\rightarrow$ List[HouseObject]: Filters the raw detections based on the confidence threshold and converts them to HouseObject instances
\end{itemize}

\newpage

\section{MIS of Scoring} \label{Module} 

\subsection{Module}

ScoringModule

\subsection{Uses}
To evaluate changes in a room by comparing two sets of detected objects (representing "before" and "after" states) and assign a cleanliness score based on the differences

\subsection{Syntax}

\subsubsection{Exported Constants}

\begin{itemize}
  \item MAX{\_}SCORE: int = 100 (maximum cleanliness score)
  \item MIN{\_}SCORE: int = 0 (minimum cleanliness score)
  \item OBJECT{\_}WEIGHTS: dict (Weights for scoring different objects based on their categories)
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5cm} p{3cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
calculate{\_}cleanliness & before: List[HouseObject], after: List[HouseObject] & int & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None


\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
  \item Input lists 'before' and 'after' contain valid HouseObject instances
  \item The HouseObject class provides sufficient information (e.g., label, confidence, bounding box) to compare objects between the two states
\end{itemize}


\subsubsection{Access Routine Semantics}

\noindent calculate{\_}cleanliness
\begin{itemize}
\item transition: Compares the before and after lists to identify added, removed, or moved objects; computes a cleanliness score based on these changes
\item output: Returns an integer cleanliness score between MIN{\_}SCORE and MAX{\_}SCORE
\item exception: 
\begin{itemize}
  \item ModelNotLoadedException: Raised if the model fails to load
  \item DetectionError: ScoringError: Raised if an error occurs during the scoring process
\end{itemize}

\end{itemize}


\subsubsection{Local Functions}

\begin{itemize}
  \item compare{\_}objects(before: List[HouseObject], after: List[HouseObject]) $\rightarrow$ Dict[str, List[HouseObject]]: Identifies added, removed, and moved objects between the two lists
  \item compute{\_}score(changes: Dict[str, List[HouseObject]]) $\rightarrow$ int: Computes the cleanliness score based on detected changes
\end{itemize}

\newpage

\section{MIS of ObjectDetection} \label{Module} 

\subsection{Module}

ObjectDetectionModule

\subsection{Uses}
To detect objects in an input tensor (preprocessed image) using a pretrained object detector (e.g. Faster R-CNN ResNet-50 FPN model). The output is a list of detected objects, where each object is represented as a HouseObject.

\subsection{Syntax}

\subsubsection{Exported Constants}

\begin{itemize}
  \item MODEL{\_}NAME: str = "FasterRCNN{\_}ResNet50{\_}FPN"
  \item CONFIDENCE{\_}THRESHOLD: float = 0.5 (minimum confidence score for object detection results)
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5cm} p{3cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
detect{\_}objects & input{\_}tensor: Tensor & List[HouseObject] & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
\begin{itemize}
	\item self.model: torchvision.models.detection.FasterRCNN
\end{itemize}


\subsubsection{Environment Variables}
None

\subsubsection{Assumptions}
\begin{itemize}
  \item The input tensor is correctly preprocessed and normalized according to the requirements of the Faster R-CNN model
  \item PyTorch and torchvision libraries are installed and functional
\end{itemize}


\subsubsection{Access Routine Semantics}

\noindent detect{\_}objects
\begin{itemize}
\item transition: Uses the pretrained Faster R-CNN model to detect objects in the input tensor, filters results based on the confidence threshold
\item output: Returns a list of detected objects, where each object is represented as a HouseObject
\item exception: 
\begin{itemize}
  \item ModelNotLoadedException: Raised if the model fails to load
  \item DetectionError: Raised if an error occurs during detection process
\end{itemize}

\end{itemize}


\subsubsection{Local Functions}

\begin{itemize}
  \item load{\_}model() $\rightarrow$ torchvision.models.detection.FasterRCNN: Loads pretrained Faster R-CNN ResNet-50 FPN model
  \item filter{\_}detections(detections: List[Dict], threshold: float) $\rightarrow$ List[HouseObject]: Filters the raw detections based on the confidence threshold and converts them to HouseObject instances
\end{itemize}

\newpage

\section{MIS of BackendCommunication} \label{Module} 

\subsection{Module}

BackendCommunicationModule

\subsection{Uses}
To provide an interface for the app's backend to interact with the Python-based object detection, machine learning, and scoring functionalities. The module packages these functionalities using FastAPI and exposes them as RESTful endpoints.

\subsection{Syntax}

\subsubsection{Exported Constants}

\begin{itemize}
  \item API{\_}VERSION: str = "v1"
  \item BASE{\_}URL: str = "/api/v1"
\end{itemize}

\subsubsection{Exported Access Programs}

\begin{center}
\begin{tabular}{p{5cm} p{3cm} p{3cm} p{2cm}}
\hline
\textbf{Name} & \textbf{In} & \textbf{Out} & \textbf{Exceptions} \\
\hline
start{\_}server & - & None & - \\
\hline
POST /process{\_}images & image{\_}set: JSON & cleanliness{\_}score: JSON & - \\
\hline
\end{tabular}
\end{center}

\subsection{Semantics}

\subsubsection{State Variables}
None


\subsubsection{Environment Variables}
\begin{itemize}
  \item FastAPI: Required for exposing RESTful endpoints
  \item Backend: The JavaScript backend that interacts with the module
\end{itemize}

\subsubsection{Assumptions}
\begin{itemize}
  \item FastAPI and its dependencies (e.g., Uvicorn) are installed and properly configured
  \item The backend sends valid JSON requests with correctly encoded image data
\end{itemize}


\subsubsection{Access Routine Semantics}

\noindent start{\_}server
\begin{itemize}
\item transition: Initiates the FastAPI application and starts the server to handle incoming requests
\item output: None
\item exception: 
\begin{itemize}
  \item ServerError: Raised if the server fails to start
\end{itemize}

\end{itemize}

\noindent Endpoint: POST /process{\_}images
\begin{itemize}
\item transition:
\begin{itemize}
  \item Decodes the base64-encoded input images
  \item Passes the images through the ObjectDetection and Scoring modules
  \item Computes and returns the cleanliness score
\end{itemize}
\item output: A JSON object with the following structure: \\ \{ \\"cleanliness{\_}score": int\\ \}
\item exception: 
\begin{itemize}
  \item InvalidInputError: Raised if the input JSON is malformed or invalid
  \item ProcessingError: Raised if an error occurs during processing
\end{itemize}

\end{itemize}


\subsubsection{Local Functions}

\begin{itemize}
  \item decode{\_}images(encoded{\_}images: List[str]) $\rightarrow$ List[Tensor]: Decodes base64-encoded images into PyTorch tensors
  \item process{\_}request(images: List[Tensor]) $\rightarrow$ int: Processes the input images through the ObjectDetection and Scoring modules to compute the cleanliness score
\end{itemize}

\newpage

\bibliographystyle {plainnat}
\bibliography {../../../refs/References}


\newpage

\section{Appendix} \label{Appendix}

\wss{Extra information if required}

\newpage{}

\section*{Appendix --- Reflection}

\wss{Not required for CAS 741 projects}

The information in this section will be used to evaluate the team members on the
graduate attribute of Problem Analysis and Design.

\input{../../Reflection.tex}

\begin{enumerate}
  \item \textbf{What went well while writing this deliverable?}\\
  When writing this deliverable, the team addressed and resolved questions about our project that we had been putting off for a long time. Decisions such as "how \textit{exactly} will we be implementing this" were answered, and now the team is fully aligned on how each module will interact. Another thing that went well when writing this deliverable was that, unlike previous deliverables, there were no conflicts or issues raised because of past deliverables. This is because the team went back and modified past deliverables to check that all deliverables were in line with each other and wouldn't cause obstacles in the future.
  \item \textbf{What pain points did you experience during this deliverable, and how
    did you resolve them?}\\
    Some pain points when writing this deliverable included a lack of clarity about specific solution details and uncertainty about the granularity of modules. When writing the MG and the MIS, the team was still unclear about the exact outputs of the cleanliness detection algorithm. While working on the document, the team was unsure if we would implement advanced functionality like detecting stains and which user created them or if we would fall back to more basic functionality. Additionally, the team was unclear if we should include modules not implemented by us completely, such as authentication frameworks, databases, web frameworks, and programming languages. The lack of clarity about the cleanliness detection algorithm, while not completely resolved, was handled by specifying our unknowns in the anticipated changes section of our module guide and creating clear pathways for development based on what happens in the future. Additionally, we decided not to pursue one of our ideas due to privacy and other concerns raised by our project supervisor. The clarity issues about the document itself were rectified by communicating with our TA, including more modules, and distinguishing modules that were not implemented but used in the MG.      
  \item \textbf{Which of your design decisions stemmed from speaking to your client(s)
  or a proxy (e.g. your peers, stakeholders, potential users)? For those that
  were not, why, and where did they come from?}\\
  Almost all decisions stemmed from speaking to client(s) or a proxy. Our proxy for design decisions related to the cleanliness management system and all related systems is Dr. Tharmarasa, an expert in computer vision and object detection. Decisions related to the features of the client-facing application come from discussions with students in shared-living situations which are abundant at McMaster University.
  \item \textbf{While creating the design doc, what parts of your other documents (e.g.
  requirements, hazard analysis, etc), it any, needed to be changed, and why?}\\
  No other documents were altered while working on the MG and MIS. Before working on this document, previous documents were modified to align with each other and to resolve issues raised by supervisors and peers. This made it easy to ensure development of the MG, and MIS caused no conflicts with prior documents. 
  \item \textbf{What are the limitations of your solution?  Put another way, given
  unlimited resources, what could you do to make the project better?} (LO\_ProbSolutions)\\
  Current limitations in the solution include limitations in the detection ability of the cleanliness detection algorithm. As of writing, this module is implemented using pre-trained object detection models and focuses on detecting differences in the state, leaving the users to determine whether or not the state of the room has improved or worsened. This is due to a lack of time and expertise in implementing a custom AI model for this use case. Given unlimited time and resources, a dedicated artificial intelligence and object detection model specializing in detecting "messes" would be built to reduce manual effort from the user and improve the system's accuracy.\\\\
  Another limitation of the system is its inability to enforce accountability amongst roommates. Currently, the solution provides a suite of tools for roommates to use and to keep track of information but does not provide any way of enforcing things like bill payments or chores. Given more time, the team could have implemented some point or merit tracking system that would report the landlord who isn't paying bills and keeping their property in proper order, and the landlord could provide notices to tenants and help with enforcement.
  \item \textbf{Give a brief overview of other design solutions you considered.  What
  are the benefits and trade-offs of those other designs compared with the chosen
  design?  From all the potential options, why did you select the documented design?}
  (LO\_Explores)\\
  Some alternative solutions were the creation of a mobile app over a progressive web application (PWA), the creation of our machine learning model over a pre-trained model, and having the camera system track which user modified the shared living space and keeping track of which user contributed the most to issues in shared living spaces. The first two alternatives provide the development team with more flexibility and customizability but increase development time due to the team's lack of experience building AI models and mobile apps. Ultimately, the team decided to use a pre-trained AI model and build a PWA because the deadlines in this project are firm, and being unable to deliver any product is worse than a product with less functionality. Finally, the team decided not to pursue implementing the solution, which involved tracking which users did what in the shared living situations due to concerns raised by our supervisor. These concerns included privacy concerns and accuracy concerns. Since the team is using a pre-trained AI model, we decided it would be best to not associate data with users to prevent frustrations caused by false positives/negatives (defined in the \href{https://github.com/jinalkast/room8/tree/main/docs/HazardAnalysis}{Harzard Analysis}).
\end{enumerate}


\end{document}